#!/usr/bin/env python3
"""
Extract modes with Spectral Proper Orthogonal Decomposition (SPOD)

For now we only use standard version and NOT streaming version, as available in
https://github.com/MathEXLab/PySPOD/tree/main/pyspod/spod

Author: R. Frantz

Reference codes:
    - https://github.com/SpectralPOD/spod_matlab/tree/master
    - https://github.com/MathEXLab/PySPOD/blob/main/tutorials/tutorial1/tutorial1.ipynb
"""

# All core imports and configs are available via utils
from utils import *


class SPODAnalyzer(BaseAnalyzer):
    ############################################################
    # Disk caching for FFT blocks                             #
    #                                                        #
    # Motivation: For very large datasets, computing FFT      #
    # blocks is expensive and may exceed memory limits.       #
    # By saving FFT blocks to disk (caching), we avoid        #
    # recomputation on repeated runs with the same data and   #
    # parameters. This is especially beneficial for large     #
    # simulations or parameter sweeps, where the FFT step     #
    # dominates runtime.                                      #
    #                                                        #
    # Note: The first run will be slightly slower due to      #
    # saving to disk, but subsequent runs are much faster     #
    # as FFT blocks are loaded directly from cache.           #
    # For small datasets or one-off runs, caching can be      #
    # disabled if desired.                                    #
    ############################################################
    # Disk caching for FFT blocks #
    ###############################
    def _get_blocks_directory(self):
        # All FFT block cache is stored in the central cache directory
        blocks_dir = os.path.join(CACHE_DIR, f"{self.data_root}_blocks")
        os.makedirs(blocks_dir, exist_ok=True)
        return blocks_dir

    def _check_cached_blocks_exist(self):
        blocks_dir = self._get_blocks_directory()
        metadata_file = os.path.join(blocks_dir, "metadata.json")
        if not os.path.exists(metadata_file):
            return False
        try:
            with open(metadata_file, "r") as f:
                metadata = json.load(f)
            current_metadata = {
                "nfft": self.nfft,
                "overlap": self.overlap,
                "blockwise_mean": getattr(self, "blockwise_mean", False),
                "normvar": getattr(self, "normvar", False),
                "window_norm": getattr(self, "window_norm", "power"),
                "window_type": getattr(self, "window_type", "hamming"),
                "file_path": self.file_path,
                "n_blocks": self.nblocks,
            }
            for key, value in current_metadata.items():
                if key not in metadata or metadata[key] != value:
                    return False
            expected_count = self.nblocks * (self.nfft // 2 + 1)
            block_files = glob.glob(os.path.join(blocks_dir, "block_*.npy"))
            if len(block_files) < expected_count:
                return False
            return True
        except Exception:
            return False

    def _save_fft_block(self, freq_idx, block_idx, data):
        blocks_dir = self._get_blocks_directory()
        filename = f"block_{freq_idx:04d}_{block_idx:04d}.npy"
        np.save(os.path.join(blocks_dir, filename), data)

    def _load_fft_block(self, freq_idx, block_idx):
        blocks_dir = self._get_blocks_directory()
        filename = f"block_{freq_idx:04d}_{block_idx:04d}.npy"
        return np.load(os.path.join(blocks_dir, filename))

    def _save_blocks_metadata(self):
        blocks_dir = self._get_blocks_directory()
        metadata = {
            "nfft": self.nfft,
            "overlap": self.overlap,
            "blockwise_mean": getattr(self, "blockwise_mean", False),
            "normvar": getattr(self, "normvar", False),
            "window_norm": getattr(self, "window_norm", "power"),
            "window_type": getattr(self, "window_type", "hamming"),
            "file_path": self.file_path,
            "n_blocks": self.nblocks,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        }
        with open(os.path.join(blocks_dir, "metadata.json"), "w") as f:
            json.dump(metadata, f, indent=2)

    ###############################
    # Robust error handling       #
    ###############################
    def _validate_inputs(self):
        if not hasattr(self, "data") or "q" not in self.data:
            raise ValueError("Data not loaded or 'q' field missing.")
        if self.nfft <= 0:
            raise ValueError(f"Invalid nfft: {self.nfft}. Must be positive.")
        if self.overlap < 0 or self.overlap >= 1:
            raise ValueError(f"Invalid overlap: {self.overlap}. Must be in [0, 1).")
        valid_windows = ["hamming", "hann", "rectangular", "sine"]
        if self.window_type not in valid_windows:
            raise ValueError(f"Invalid window_type: {self.window_type}. Must be one of {valid_windows}.")
        valid_norms = ["power", "amplitude"]
        if self.window_norm not in valid_norms:
            raise ValueError(f"Invalid window_norm: {self.window_norm}. Must be one of {valid_norms}.")
        if self.data["Ns"] < self.nfft:
            raise ValueError(f"Too few time samples ({self.data['Ns']}) for FFT size ({self.nfft}).")
        required_fields = ["x", "y", "Nx", "Ny", "dt"]
        missing_fields = [field for field in required_fields if field not in self.data]
        if missing_fields:
            raise ValueError(f"Missing required data fields: {', '.join(missing_fields)}")

    ###############################
    # Flexible data handling      #
    ###############################
    def load_and_preprocess(self):
        super().load_and_preprocess()
        self._validate_inputs()
        # Flexible handling for ndarray input
        if isinstance(self.data, dict):
            pass
        elif isinstance(self.data, np.ndarray):
            if self.data.ndim >= 2:
                if self.data.ndim > 2:
                    time_steps = self.data.shape[0]
                    spatial_points = np.prod(self.data.shape[1:])
                    self.data = {"q": self.data.reshape(time_steps, spatial_points)}
                else:
                    self.data = {"q": self.data}
            else:
                raise ValueError("Input array must have at least 2 dimensions (time, space)")
        else:
            raise ValueError(f"Unsupported data type: {type(self.data)}. Must be dict or ndarray.")
        # Strouhal normalization
        if "cavity" in self.file_path.lower():
            self.L = 0.0381
            self.U = 230.0
            print(f"Cavity case detected: Using L={self.L} m, U={self.U} m/s for Strouhal normalization.")
        else:
            self.L = 1.0
            self.U = 1.0
            print("Jet case or unknown: Using L=1, U=1 for Strouhal normalization.")
        self.fs = 1 / self.data["dt"]
        f = np.linspace(0, self.fs - self.fs / self.nfft, self.nfft)
        St = f * self.L / self.U
        self.St = St[0 : self.nfft // 2 + 1]
        self.dst = self.St[1] - self.St[0]
        self.strouhal = St

    ###############################
    # Progress reporting + caching#
    ###############################
    def compute_fft_blocks(self):
        if self._check_cached_blocks_exist():
            print("Loading FFT blocks from disk cache...")
            n_freq = self.nfft // 2 + 1
            nq = self.data["Nx"] * self.data["Ny"]
            self.qhat = np.zeros((n_freq, nq, self.nblocks), dtype=complex)
            for i in tqdm(range(n_freq), desc="Loading FFT blocks", unit="freq"):
                for j in range(self.nblocks):
                    self.qhat[i, :, j] = self._load_fft_block(i, j)
            print("FFT blocks loaded from cache successfully.")
            return
        if "q" not in self.data:
            raise ValueError("Data not loaded. Call load_and_preprocess() first.")
        print(f"Computing FFT with {self.nblocks} blocks...")
        self.qhat = blocksfft(self.data["q"], self.nfft, self.nblocks, self.novlap, blockwise_mean=getattr(self, "blockwise_mean", False), normvar=getattr(self, "normvar", False), window_norm=getattr(self, "window_norm", "power"), window_type=getattr(self, "window_type", "hamming"))
        print("Saving FFT blocks to disk cache...")
        n_freq = self.nfft // 2 + 1
        for i in tqdm(range(n_freq), desc="Saving FFT blocks", unit="freq"):
            for j in range(self.nblocks):
                self._save_fft_block(i, j, self.qhat[i, :, j])
        self._save_blocks_metadata()
        print("FFT blocks saved to disk cache successfully.")
        print("FFT computation complete.")

    def perform_spod(self):
        if self.qhat.size == 0:
            raise ValueError("FFT blocks not computed. Call compute_fft_blocks() first.")
        start_time = time.time()
        nq = self.data["Nx"] * self.data["Ny"]
        n_freq = self.nfft // 2 + 1
        self.lambda_values = np.zeros((n_freq, self.nblocks))
        self.phi = np.zeros((n_freq, nq, self.nblocks), dtype=complex)
        self.psi = np.zeros((n_freq, self.nblocks, self.nblocks), dtype=complex)
        print("Performing SPOD for each frequency...")
        for i in tqdm(range(n_freq), desc="SPOD Computation", unit="freq"):
            qhat_freq = self.qhat[i, :, :]
            phi_freq, lambda_freq, psi_freq = spod_function(qhat_freq, self.nblocks, self.dst, self.W, return_psi=True)
            self.phi[i, :, :] = phi_freq
            self.lambda_values[i, :] = lambda_freq
            self.psi[i, :, :] = psi_freq
        print(f"SPOD eigenvalue decomposition completed in {time.time() - start_time:.2f} seconds")

    def save_results(self):
        if self.phi.size == 0 or self.lambda_values.size == 0:
            raise ValueError("SPOD not performed. Call perform_spod() first.")
        from utils import make_result_filename

        save_path = os.path.join(self.results_dir, make_result_filename(self.data_root, self.nfft, self.overlap, self.data["Ns"], "spod"))
        print(f"Saving results to {save_path}")
        with h5py.File(save_path, "w") as fsnap:
            fsnap.create_dataset("Phi", data=self.phi, compression="gzip")
            fsnap.create_dataset("Lambda", data=self.lambda_values, compression="gzip")
            fsnap.create_dataset("St", data=self.St, compression="gzip")
            fsnap.create_dataset("x", data=self.data["x"], compression="gzip")
            fsnap.create_dataset("y", data=self.data["y"], compression="gzip")
            fsnap.attrs["Nfft"] = self.nfft
            fsnap.attrs["overlap"] = self.overlap
            fsnap.attrs["Ns"] = self.data["Ns"]
            fsnap.attrs["fs"] = self.fs
            fsnap.attrs["nblocks"] = self.nblocks
            fsnap.attrs["dt"] = self.data["dt"]

    def plot_eigenvalues(self, n_modes=10, highlight_St=None):
        """Plot the SPOD eigenvalue spectrum (energy vs. St) for leading modes.
        Optionally highlight a specific St value (e.g., the selected mode peak)."""
        if self.lambda_values.size == 0:
            raise ValueError("SPOD not performed. Call perform_spod() first.")
        print("Plotting SPOD eigenvalues...")
        plt.figure(figsize=(10, 6))
        plt.rc("text", usetex=USE_LATEX)
        plt.rc("font", family=FONT_FAMILY, size=FONT_SIZE)
        n_modes_to_plot = min(n_modes, self.lambda_values.shape[1])
        for i in range(n_modes_to_plot):
            plt.loglog(self.St, self.lambda_values[:, i], label=f"Mode {i + 1}", marker="o", markersize=3, linestyle="-")
        if highlight_St is not None:
            idx = np.argmin(np.abs(self.St - highlight_St))
            plt.scatter(self.St[idx], self.lambda_values[idx, 0], color="red", s=80, edgecolor="k", zorder=10, label=f"Peak St={self.St[idx]:.3f}")
        plt.legend()
        plt.xlabel(r"St")
        plt.ylabel(r"SPOD Eigenvalue $\lambda$")
        plt.title(r"SPOD Eigenvalue Spectrum vs. St")
        plt.grid(True, which="both", ls="--", alpha=0.5)
        plt.tight_layout()
        os.makedirs(self.figures_dir, exist_ok=True)
        filename = f"{self.data_root}_eigenvalues_Nfft{self.nfft}_ovlap{self.overlap}_{self.data['Ns']}snapshots.{FIG_FORMAT}"
        plt.savefig(os.path.join(self.figures_dir, os.path.basename(filename)), bbox_inches="tight", dpi=FIG_DPI, format=FIG_FORMAT)
        plt.close()
        print(f"Eigenvalue plot saved to {filename}")

    def plot_modes(self, st_target, n_modes=4):
        """Plot the real part of spatial SPOD modes (Phi) for a target Strouhal number."""
        if self.phi.size == 0:
            raise ValueError("SPOD not performed. Call perform_spod() first.")

        # Find the index (st_idx) of the Strouhal number in self.St closest to st_target
        st_idx = np.argmin(np.abs(self.St - st_target))
        st_value = self.St[st_idx]
        print(f"Plotting SPOD modes for St â‰ˆ {st_value:.4f} (target: {st_target:.4f})...", flush=True)

        # Setup grid layout for subplots
        n_modes_to_plot = min(n_modes, self.phi.shape[2], 4)

        if n_modes_to_plot == 0:
            print("  Warning: No modes available to plot.")
            return

        # Set layout to 2x2 grid
        nrows = 2
        ncols = 2

        # Create figure and axes
        fig, axes = plt.subplots(nrows, ncols, figsize=(ncols * 4, nrows * 4), squeeze=False, constrained_layout=True)
        axes = axes.flatten()

        plt.rc("text", usetex=False)
        plt.rc("font", family="serif", size=10)
        cmap = plt.get_cmap("bwr")

        # Plot each requested mode
        max_abs_val = 0
        phi_modes_real = []
        for i in range(n_modes_to_plot):
            phi_real = self.phi[st_idx, :, i].real
            phi_2d = np.reshape(phi_real, (self.data["Nx"], self.data["Ny"])).T
            phi_modes_real.append(phi_2d)
            max_abs_val = max(max_abs_val, np.max(np.abs(phi_real)))

        interval = max_abs_val * 1.0
        levels = np.linspace(-interval, interval, 61)

        for i in range(n_modes_to_plot):
            phi_2d = phi_modes_real[i]
            ax = axes[i]
            im = ax.contourf(self.data["x"], self.data["y"], phi_2d, levels=levels, cmap=cmap, vmin=-interval, vmax=interval, extend="both")
            ax.set_aspect("equal")
            ax.set_title(f"Mode {i + 1}", size=12)
            if i >= (nrows - 1) * ncols:
                ax.set_xlabel("$x$", fontsize=12)
            if i % ncols == 0:
                ax.set_ylabel("$r$", fontsize=12)
            else:
                ax.set_yticklabels([])
            ax.tick_params(axis="both", which="major", labelsize=10)

        for i in range(n_modes_to_plot, len(axes)):
            axes[i].axis("off")

        fig.colorbar(im, ax=axes[:n_modes_to_plot], shrink=0.8, label=r"Real($\Phi$)")
        fig.suptitle(rf"SPOD Modes at $St \approx {st_value:.4f}$", fontsize=14)

        # Ensure figures directory exists
        os.makedirs(self.figures_dir, exist_ok=True)
        filename = f"{self.data_root}_modes_Nfft{self.nfft}_ovlap{self.overlap}_{self.data['Ns']}snapshots_St{st_value:.4f}.png"
        fig.savefig(os.path.join(self.figures_dir, os.path.basename(filename)), bbox_inches="tight", dpi=300)
        plt.close(fig)
        print(f"  Mode plot saved to {filename}")

    def plot_eig_complex_plane(self, n_modes=4, st_target=None):
        """
        Plot the eigenvalues for a given Strouhal number (or the dominant one) in the complex plane:
        - x-axis: Real part
        - y-axis: Imaginary part
        Each eigenvalue corresponds to a mode at the selected frequency.
        """
        if self.lambda_values.size == 0 or self.phi.size == 0:
            raise ValueError("SPOD not performed. Call perform_spod() first.")
        # Determine which St to use
        if st_target is None:
            # Use the dominant peak as in plot_modes
            peaks, _ = find_peaks(self.lambda_values[:, 0])
            valid_peaks = [i for i in peaks if self.St[i] > 0.1]
            if valid_peaks:
                idx_peak = valid_peaks[np.argmax(self.lambda_values[valid_peaks, 0])]
                st_idx = idx_peak
                st_value = self.St[st_idx]
            else:
                st_idx = np.argmax(self.lambda_values[:, 0])
                st_value = self.St[st_idx]
        else:
            st_idx = np.argmin(np.abs(self.St - st_target))
            st_value = self.St[st_idx]
        # Get eigenvalues (complex) for the selected frequency
        # For SPOD, lambda_values are real, but phi (modes) are complex
        # We'll plot the first n_modes eigenvectors' first spatial point (as a simple example)
        eigvecs = self.phi[st_idx, :, :n_modes]  # shape: (space, n_modes)
        # For each mode, plot the real vs imag part of all spatial points
        plt.figure(figsize=(6, 6))
        for i in range(eigvecs.shape[1]):
            plt.scatter(eigvecs[:, i].real, eigvecs[:, i].imag, label=f"Mode {i + 1}", alpha=0.7, s=18)
        plt.xlabel("Real part of Mode")
        plt.ylabel("Imaginary part of Mode")
        plt.title(rf"SPOD Mode Eigenvectors in Complex Plane ($St \approx {st_value:.4f}$)")
        plt.legend()
        plt.grid(True, ls="--", alpha=0.5)
        plt.tight_layout()
        # Ensure figures directory exists
        os.makedirs(self.figures_dir, exist_ok=True)
        filename = f"{self.data_root}_modes_complex_plane_Nfft{self.nfft}_ovlap{self.overlap}_{self.data['Ns']}snapshots_St{st_value:.4f}.png"
        plt.savefig(os.path.join(self.figures_dir, os.path.basename(filename)), bbox_inches="tight", dpi=300)
        plt.close()
        print(f"  Complex plane plot saved to {filename}")

    def plot_time_coeffs(self, st_target=None, coeffs_idx=[0], n_blocks_plot=None):
        """
        Plot the real and imaginary parts of the time coefficients (psi) for selected modes at a given St.
        coeffs_idx: list of mode indices to plot (e.g., [0, 1])
        n_blocks_plot: if not None, limit number of blocks/time samples to plot
        """
        if not hasattr(self, "psi") or self.psi.size == 0:
            print("No time coefficients found. Run SPOD first.")
            return
        if st_target is None:
            # Use the dominant peak as in plot_modes
            peaks, _ = find_peaks(self.lambda_values[:, 0])
            valid_peaks = [i for i in peaks if self.St[i] > 0.1]
            if valid_peaks:
                idx_peak = valid_peaks[np.argmax(self.lambda_values[valid_peaks, 0])]
                st_idx = idx_peak
                st_value = self.St[st_idx]
            else:
                st_idx = np.argmax(self.lambda_values[:, 0])
                st_value = self.St[st_idx]
        else:
            st_idx = np.argmin(np.abs(self.St - st_target))
            st_value = self.St[st_idx]
        time_coeffs = self.psi[st_idx, :, :]  # shape: (nblocks, nblocks)
        if n_blocks_plot is not None:
            time_coeffs = time_coeffs[:n_blocks_plot, :]
        plt.figure(figsize=(8, 5))
        for idx in coeffs_idx:
            plt.plot(time_coeffs[:, idx].real, label=f"Mode {idx + 1} (real)")
            plt.plot(time_coeffs[:, idx].imag, "--", label=f"Mode {idx + 1} (imag)")
        plt.xlabel("Block index (time)")
        plt.ylabel("Time coefficient")
        plt.title(rf"SPOD Time Coefficients at $St \approx {st_value:.4f}$")
        plt.legend()
        plt.grid(True, ls="--", alpha=0.5)
        plt.tight_layout()
        # Ensure figures directory exists
        os.makedirs(self.figures_dir, exist_ok=True)
        filename = f"{self.data_root}_time_coeffs_Nfft{self.nfft}_ovlap{self.overlap}_{self.data['Ns']}snapshots_St{st_value:.4f}.png"
        plt.savefig(os.path.join(self.figures_dir, os.path.basename(filename)), bbox_inches="tight", dpi=300)
        plt.close()
        print(f"  Time coefficients plot saved to {filename}")

    def plot_cumulative_energy_per_frequency(self, st_target=None):
        """Plot the cumulative energy captured by SPOD modes for a specific frequency."""
        if self.lambda_values is None or self.St is None:
            print("Eigenvalues or Strouhal numbers not available. Run perform_spod() first.")
            return

        if st_target is None:
            # Default to the frequency with max energy in the first mode if not specified
            dominant_freq_idx = np.argmax(self.lambda_values[:, 0])
            st_target = self.St[dominant_freq_idx]
            print(f"No st_target provided for cumulative energy plot. Using St = {st_target:.4f} (dominant for mode 0).")

        freq_idx = np.argmin(np.abs(self.St - st_target))
        actual_st = self.St[freq_idx]
        eigenvalues_at_freq = self.lambda_values[freq_idx, :]

        if eigenvalues_at_freq.size == 0:
            print(f"No eigenvalues found for St = {actual_st:.4f}.")
            return

        cumulative_energy = np.cumsum(eigenvalues_at_freq) / np.sum(eigenvalues_at_freq) * 100
        mode_indices = np.arange(1, len(eigenvalues_at_freq) + 1)

        plt.figure(figsize=(8, 5))
        plt.plot(mode_indices, cumulative_energy, "o-", linewidth=2, markersize=6)
        plt.xlabel("Number of Modes")
        plt.ylabel("Cumulative Energy (%)")
        plt.title(f"Cumulative Energy of SPOD Modes at St = {actual_st:.4f}")
        plt.grid(True, which="both", ls="--")
        plt.ylim(0, 105)
        plot_filename = os.path.join(self.figures_dir, f"{self.data_root}_spod_cumulative_energy_St{actual_st:.4f}.png")
        plt.savefig(plot_filename)
        plt.close()
        print(f"SPOD cumulative energy plot for St={actual_st:.4f} saved to {plot_filename}")

    def check_spatial_mode_orthogonality(self, st_target=None, tolerance=1e-9):
        """Check orthogonality of spatial SPOD modes for a specific frequency.
        Verifies Modes_f.conj().T @ W @ Modes_f is close to Identity.
        """
        if self.phi is None or self.phi.size == 0 or self.W is None or self.St is None:
            print("Modes (self.phi), weights, or Strouhal numbers not available. Run perform_spod() first.")
            return False

        if st_target is None:
            dominant_freq_idx = np.argmax(self.lambda_values[:, 0])
            st_target = self.St[dominant_freq_idx]
            print(f"No st_target provided for spatial orthogonality check. Using St = {st_target:.4f} (dominant for mode 0).")

        freq_idx = np.argmin(np.abs(self.St - st_target))
        actual_st = self.St[freq_idx]
        # self.phi has shape (Nfreq, Nspace, Nmodes_at_freq)
        # So, self.phi[freq_idx, :, :] gives (Nspace, Nmodes_at_freq)
        modes_at_freq = self.phi[freq_idx, :, :]
        n_modes_at_freq = modes_at_freq.shape[1]

        if n_modes_at_freq == 0:
            print(f"No modes found for St = {actual_st:.4f} to check orthogonality.")
            return False

        print(f"\nChecking SPOD spatial mode orthogonality for St = {actual_st:.4f} (Modes.conj().T @ W @ Modes)...")

        # Ensure W is a diagonal matrix for the check
        if self.W.ndim == 1:
            W_diag_matrix = np.diag(self.W)
        elif self.W.ndim == 2 and self.W.shape[0] == self.W.shape[1] and np.allclose(self.W, np.diag(np.diag(self.W))):
            W_diag_matrix = self.W
        elif self.W.ndim == 2 and self.W.shape[1] == 1:  # (Nspace, 1) column vector
            W_diag_matrix = np.diag(self.W.flatten())
        else:
            print(f"  Warning: Unexpected shape or type for spatial weights W: {self.W.shape}. Cannot perform accurate orthogonality check.")
            return False

        ortho_check_matrix = modes_at_freq.conj().T @ W_diag_matrix @ modes_at_freq
        identity_matrix = np.eye(n_modes_at_freq)

        diag_diff = np.abs(np.diag(ortho_check_matrix) - 1.0)
        max_diag_deviation = np.max(diag_diff)

        off_diag_mask = ~np.eye(n_modes_at_freq, dtype=bool)
        max_off_diag_val = np.max(np.abs(ortho_check_matrix[off_diag_mask])) if n_modes_at_freq > 1 else 0.0

        is_orthogonal = (max_diag_deviation < tolerance) and (max_off_diag_val < tolerance)

        print(f"  Max deviation of diagonal elements from 1: {max_diag_deviation:.2e}")
        print(f"  Max absolute value of off-diagonal elements: {max_off_diag_val:.2e}")
        if is_orthogonal:
            print(f"  SPOD spatial modes at St={actual_st:.4f} appear to be W-orthogonal.")
        else:
            print(f"  Warning: SPOD spatial modes at St={actual_st:.4f} may not be perfectly W-orthogonal.")

        plt.figure(figsize=(7, 6))
        # Use a consistent scaling for the colorbar if possible, e.g., vmin=-1, vmax=1 if expecting identity-like matrix
        # However, deviations can be small, so autoscaling might be better initially.
        abs_max_val = np.max(np.abs(ortho_check_matrix))
        plt.imshow(ortho_check_matrix.real, cmap=CMAP_DIV, vmin=-abs_max_val, vmax=abs_max_val)
        plt.colorbar(label="Value (Real Part)")
        plt.title(f"SPOD Spatial Mode Orthogonality (St={actual_st:.4f})")
        plt.xlabel("Mode Index")
        plt.ylabel("Mode Index")
        plot_filename = os.path.join(self.figures_dir, f"{self.data_root}_spod_spatial_ortho_St{actual_st:.4f}.png")
        plt.savefig(plot_filename)
        plt.close()
        print(f"  SPOD spatial orthogonality check plot for St={actual_st:.4f} saved to {plot_filename}")
        return is_orthogonal

    def check_temporal_coefficient_orthogonality(self, st_target=None, tolerance=1e-9):
        """Check orthogonality of SPOD temporal coefficients (Psi_f) for a specific frequency.
        Verifies Psi_f.conj().T @ Psi_f is close to Identity.
        """
        if self.psi is None or self.psi.size == 0 or self.St is None:
            print("Temporal coefficients (self.psi) or Strouhal numbers not available. Run perform_spod() first.")
            return False

        if st_target is None:
            dominant_freq_idx = np.argmax(self.lambda_values[:, 0])  # Assuming lambda_values exists if psi does
            st_target = self.St[dominant_freq_idx]
            print(f"No st_target provided for temporal coefficient orthogonality check. Using St = {st_target:.4f} (dominant for mode 0).")

        freq_idx = np.argmin(np.abs(self.St - st_target))
        actual_st = self.St[freq_idx]
        # self.psi has shape (Nfreq, Nmodes_at_freq, Nblocks_or_Nmodes_again)
        # For standard SPOD, Nmodes_at_freq is Nblocks. Psi_f is (Nblocks, Nblocks)
        # psi_at_freq should be (Nblocks, Nmodes_at_freq)
        psi_at_freq = self.psi[freq_idx, :, :]
        n_coeffs = psi_at_freq.shape[0]  # Should be nblocks
        n_modes_check = psi_at_freq.shape[1]  # Also nblocks for full rank

        if n_coeffs == 0 or n_modes_check == 0:
            print(f"No temporal coefficients found for St = {actual_st:.4f} to check orthogonality.")
            return False

        # We are checking L.conj().T @ L = I, where L is psi_at_freq
        # If n_modes_check (columns) < n_coeffs (rows), the result won't be square Identity of size n_coeffs
        # but rather Identity of size n_modes_check

        print(f"\nChecking SPOD temporal coefficient orthogonality for St = {actual_st:.4f} (Psi_f.conj().T @ Psi_f)...")
        ortho_check_matrix = psi_at_freq.conj().T @ psi_at_freq

        # The resulting matrix should be n_modes_check x n_modes_check (e.g. nblocks x nblocks)
        identity_matrix = np.eye(n_modes_check)

        diag_diff = np.abs(np.diag(ortho_check_matrix) - 1.0)
        max_diag_deviation = np.max(diag_diff) if diag_diff.size > 0 else 0.0

        off_diag_mask = ~np.eye(n_modes_check, dtype=bool)
        max_off_diag_val = np.max(np.abs(ortho_check_matrix[off_diag_mask])) if n_modes_check > 1 and off_diag_mask.any() else 0.0

        is_orthogonal = (max_diag_deviation < tolerance) and (max_off_diag_val < tolerance)

        print(f"  Matrix shape: {ortho_check_matrix.shape}")
        print(f"  Max deviation of diagonal elements from 1: {max_diag_deviation:.2e}")
        print(f"  Max absolute value of off-diagonal elements: {max_off_diag_val:.2e}")
        if is_orthogonal:
            print(f"  SPOD temporal coefficients at St={actual_st:.4f} appear to be orthogonal (Psi_f.conj().T @ Psi_f = I).")
        else:
            print(f"  Warning: SPOD temporal coefficients at St={actual_st:.4f} may not be perfectly orthogonal.")

        plt.figure(figsize=(7, 6))
        abs_max_val = np.max(np.abs(ortho_check_matrix.real))  # Plot real part for visualization
        plt.imshow(ortho_check_matrix.real, cmap=CMAP_DIV, vmin=-abs_max_val, vmax=abs_max_val)
        plt.colorbar(label="Value (Real Part)")
        plt.title(f"SPOD Temporal Coeff Orthogonality (St={actual_st:.4f})")
        plt.xlabel("Mode Index")
        plt.ylabel("Mode Index")
        plot_filename = os.path.join(self.figures_dir, f"{self.data_root}_spod_temporal_ortho_St{actual_st:.4f}.png")
        plt.savefig(plot_filename)
        plt.close()
        print(f"  SPOD temporal coefficient orthogonality check plot for St={actual_st:.4f} saved to {plot_filename}")
        return is_orthogonal

    def plot_reconstruction_error_per_frequency(self, st_target=None, max_modes_to_check=None):
        """Plot reconstruction error of frequency-domain data (q_hat_f) vs. number of SPOD modes.
        The error is the Frobenius norm of (q_hat_f - q_hat_f_reconstructed).
        """
        if not hasattr(self, "qhat") or self.qhat is None or self.qhat.size == 0:
            print("Frequency-domain data 'self.qhat' not available. Run compute_fft_blocks() or ensure cache is loaded.")
            return
        if self.phi is None or self.phi.size == 0 or self.St is None or self.W is None:
            print("Modes (self.phi), Strouhal numbers, or weights not available. Run perform_spod() first.")
            return

        if st_target is None:
            dominant_freq_idx = np.argmax(self.lambda_values[:, 0])
            st_target = self.St[dominant_freq_idx]
            print(f"No st_target provided for reconstruction error plot. Using St = {st_target:.4f} (dominant for mode 0).")

        freq_idx = np.argmin(np.abs(self.St - st_target))
        actual_st = self.St[freq_idx]

        qhat_at_freq = self.qhat[freq_idx, :, :]  # Shape (Nspace, Nblocks)
        modes_at_freq = self.phi[freq_idx, :, :]  # Shape (Nspace, Nmodes_at_this_freq)
        n_available_modes = modes_at_freq.shape[1]

        if max_modes_to_check is None:
            max_modes_to_check = n_available_modes
        else:
            max_modes_to_check = min(max_modes_to_check, n_available_modes)

        if self.W.ndim == 1:
            W_diag = np.diag(self.W)
        elif self.W.ndim == 2 and self.W.shape[0] == self.W.shape[1] and np.allclose(self.W, np.diag(np.diag(self.W))):
            W_diag = self.W
        elif self.W.ndim == 2 and self.W.shape[1] == 1:
            W_diag = np.diag(self.W.flatten())
        else:
            print(f"  Warning: Unexpected W shape for reconstruction error: {self.W.shape}. Using identity for W_diag.")
            W_diag = np.eye(qhat_at_freq.shape[0])  # Fallback, may not be correct

        errors = []
        mode_counts = range(1, max_modes_to_check + 1)

        norm_qhat_original = np.linalg.norm(qhat_at_freq, "fro")
        if norm_qhat_original == 0:  # Avoid division by zero if qhat_at_freq is all zeros
            print(f"Warning: Original q_hat data at St={actual_st:.4f} has zero norm. Cannot compute relative error.")
            # errors will remain empty, plot will be skipped or show zero error
            return

        print(f"\nCalculating reconstruction error for q_hat at St = {actual_st:.4f}...")
        for k in mode_counts:
            current_modes = modes_at_freq[:, :k]
            # Project qhat_at_freq onto the current_modes (W-weighted projection)
            # Coeffs = Modes_k^H * W * Q_hat_f
            projection_coeffs = current_modes.conj().T @ W_diag @ qhat_at_freq
            # Reconstruct: Q_hat_f_rec = Modes_k * Coeffs
            qhat_reconstructed = current_modes @ projection_coeffs

            error = np.linalg.norm(qhat_at_freq - qhat_reconstructed, "fro") / norm_qhat_original
            errors.append(error)
            if k % (max_modes_to_check // 10 if max_modes_to_check > 10 else 1) == 0:
                print(f"  Computed error for k={k} modes: {error:.3e}")

        plt.figure(figsize=(8, 5))
        plt.plot(list(mode_counts), errors, "o-", linewidth=2, markersize=5)
        plt.xlabel("Number of SPOD Modes")
        plt.ylabel("Relative Reconstruction Error (Frobenius Norm)")
        plt.title(f"SPOD Reconstruction Error of $q_{{hat}}$ at St = {actual_st:.4f}")
        plt.grid(True, which="both", ls="--")
        plt.yscale("log")  # Errors often span orders of magnitude
        plot_filename = os.path.join(self.figures_dir, f"{self.data_root}_spod_reconstruction_error_St{actual_st:.4f}.png")
        plt.savefig(plot_filename)
        plt.close()
        print(f"SPOD reconstruction error plot for St={actual_st:.4f} saved to {plot_filename}")

    def plot_reconstruction_comparison_per_frequency(self, st_target=None, block_idx_to_plot=0, modes_counts_to_compare=None):
        """Visually compare original q_hat_f[:, block_idx] with reconstructions using varying numbers of SPOD modes."""
        if not hasattr(self, "qhat") or self.qhat is None or self.qhat.size == 0:
            print("Frequency-domain data 'self.qhat' not available. Run compute_fft_blocks() or ensure cache is loaded.")
            return
        if self.phi is None or self.phi.size == 0 or self.St is None or self.W is None:
            print("Modes (self.phi), Strouhal numbers, or weights not available. Run perform_spod() first.")
            return

        if st_target is None:
            dominant_freq_idx = np.argmax(self.lambda_values[:, 0])
            st_target = self.St[dominant_freq_idx]
            print(f"No st_target provided for reconstruction comparison. Using St = {st_target:.4f} (dominant for mode 0).")

        freq_idx = np.argmin(np.abs(self.St - st_target))
        actual_st = self.St[freq_idx]

        qhat_at_freq = self.qhat[freq_idx, :, :]  # Shape (Nspace, Nblocks)
        modes_at_freq = self.phi[freq_idx, :, :]  # Shape (Nspace, Nmodes_at_this_freq)
        n_available_modes = modes_at_freq.shape[1]
        n_blocks = qhat_at_freq.shape[1]

        if block_idx_to_plot < 0 or block_idx_to_plot >= n_blocks:
            print(f"Error: block_idx_to_plot={block_idx_to_plot} is out of range (0-{n_blocks - 1}). Using block 0.")
            block_idx_to_plot = 0

        if modes_counts_to_compare is None:
            modes_counts_to_compare = sorted(list(set([1, n_available_modes // 4 if n_available_modes > 3 else 1, n_available_modes // 2 if n_available_modes > 1 else 1, n_available_modes])))
            # Ensure values are at least 1 and unique
            modes_counts_to_compare = [max(1, m) for m in modes_counts_to_compare]
            modes_counts_to_compare = sorted(list(set(m for m in modes_counts_to_compare if m <= n_available_modes)))
            if not modes_counts_to_compare:
                modes_counts_to_compare = [n_available_modes]

        if self.W.ndim == 1:
            W_diag = np.diag(self.W)
        # ... (W_diag handling as in previous method) ...
        elif self.W.ndim == 2 and self.W.shape[0] == self.W.shape[1] and np.allclose(self.W, np.diag(np.diag(self.W))):
            W_diag = self.W
        elif self.W.ndim == 2 and self.W.shape[1] == 1:
            W_diag = np.diag(self.W.flatten())
        else:
            print(f"  Warning: Unexpected W shape for reconstruction comparison: {self.W.shape}. Using identity.")
            W_diag = np.eye(qhat_at_freq.shape[0])

        original_qhat_block = qhat_at_freq[:, block_idx_to_plot]  # Shape (Nspace)

        Nx = self.data.get("Nx")
        Ny = self.data.get("Ny")

        if Nx is None or Ny is None or original_qhat_block.shape[0] != Nx * Ny:
            print(f"Warning: Cannot reshape data for 2D plot in SPOD reconstruction comparison. Nx={Nx}, Ny={Ny}, DataSize={original_qhat_block.shape[0]}. Skipping 2D plot.")
            # Potentially add a 1D plot fallback here if desired or simply return
            return

        original_qhat_block_spatial = original_qhat_block.real.reshape(Nx, Ny)

        num_plots = len(modes_counts_to_compare) + 1
        # Try to make a somewhat square layout of subplots
        ncols = int(np.ceil(np.sqrt(num_plots)))
        nrows = int(np.ceil(num_plots / ncols))
        fig, axes = plt.subplots(nrows, ncols, figsize=(ncols * 4, nrows * 3.5), squeeze=False)
        axes_flat = axes.flatten()

        # Plot Original
        ax = axes_flat[0]
        im = ax.contourf(self.data["x"], self.data["y"], original_qhat_block_spatial.T, cmap=CMAP_DIV, levels=100)
        fig.colorbar(im, ax=ax)
        ax.set_title(f"Original $Re(q_{{hat}})$ Block {block_idx_to_plot}\nSt={actual_st:.4f}")
        ax.set_xlabel("x")
        ax.set_ylabel("y")

        print(f"\nPlotting reconstruction comparison for q_hat (Block {block_idx_to_plot}) at St = {actual_st:.4f}...")
        for i, k in enumerate(modes_counts_to_compare):
            if k > n_available_modes:
                continue  # Should not happen with filtering above
            current_modes = modes_at_freq[:, :k]
            projection_coeffs = current_modes.conj().T @ W_diag @ original_qhat_block  # Coeffs for this specific block
            reconstructed_qhat_block = current_modes @ projection_coeffs
            reconstructed_qhat_block_spatial = reconstructed_qhat_block.real.reshape(Nx, Ny)

            ax = axes_flat[i + 1]
            im = ax.contourf(self.data["x"], self.data["y"], reconstructed_qhat_block_spatial.T, cmap=CMAP_DIV, levels=100)
            fig.colorbar(im, ax=ax)
            ax.set_title(f"Reconstructed ({k} modes)")
            ax.set_xlabel("x")
            ax.set_ylabel("y")
            print(f"  Plotted reconstruction with k={k} modes.")

        # Hide any unused subplots
        for j in range(i + 2, nrows * ncols):
            fig.delaxes(axes_flat[j])

        fig.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to make space for suptitle
        fig.suptitle(f"SPOD $Re(q_{{hat}})$ Reconstruction Comparison at St={actual_st:.4f}, Block {block_idx_to_plot}", fontsize=14)
        plot_filename = os.path.join(self.figures_dir, f"{self.data_root}_spod_reconstruction_compare_St{actual_st:.4f}_Block{block_idx_to_plot}.png")
        plt.savefig(plot_filename)
        plt.close(fig)
        print(f"SPOD reconstruction comparison plot for St={actual_st:.4f}, Block {block_idx_to_plot} saved to {plot_filename}")

    def run_analysis(self, plot_st_target=None, plot_n_modes_eig=10, plot_n_modes_spatial=4, use_disk_cache=True, perform_verifications=True):
        """
        Run the full SPOD analysis pipeline: load, preprocess, compute FFTs,
        perform SPOD, save results, and plot.

        Args:
            plot_st_target (float, optional): Target Strouhal number for mode plots.
                                              If None, uses the St with max energy in mode 1.
            plot_n_modes_eig (int): Number of modes to show in the eigenvalue vs. St plot.
            plot_n_modes_spatial (int): Number of spatial modes to plot for the target St.
            use_disk_cache (bool): Whether to use disk caching for FFT blocks.
            perform_verifications (bool): Whether to run and plot additional verification checks.
        """
        print("Starting SPOD analysis pipeline...")
        start_total_time = time.time()
        try:
            print("\nStep 1/4: Loading and preprocessing data...")
            self.load_and_preprocess()
            print("\nStep 2/4: Computing FFT blocks...")
            if not use_disk_cache:
                import shutil

                blocks_dir = self._get_blocks_directory()
                if os.path.exists(blocks_dir):
                    shutil.rmtree(blocks_dir)
                    print("Removed existing cache, will recompute FFT blocks.")
            self.compute_fft_blocks()
            print("\nStep 3/4: Performing SPOD eigenvalue decomposition...")
            self.perform_spod()
            print("\nStep 4/4: Saving results and generating visualizations...")
            self.save_results()
            print("\nGenerating visualizations...")
            highlight_St = None
            if plot_st_target is None:
                # Find all local maxima (peaks) in mode 1
                peaks, _ = find_peaks(self.lambda_values[:, 0])
                # Filter peaks to those with St > 0.1
                valid_peaks = [i for i in peaks if self.St[i] > 0.1]
                if valid_peaks:
                    # Take the peak with the highest eigenvalue among valid peaks
                    idx_peak = valid_peaks[np.argmax(self.lambda_values[valid_peaks, 0])]
                    plot_st_target = self.St[idx_peak]
                    highlight_St = plot_st_target
                    print(f"No target St provided, plotting modes for dominant PEAK St > 0.1: {plot_st_target:.4f}")
                else:
                    # Fallback: just use the global maximum
                    dominant_freq_idx = np.argmax(self.lambda_values[:, 0])
                    plot_st_target = self.St[dominant_freq_idx]
                    highlight_St = plot_st_target
                    print(f"No St > 0.1 found, plotting modes for dominant St: {plot_st_target:.4f}")
            else:
                highlight_St = plot_st_target

            self.plot_eigenvalues(n_modes=min(plot_n_modes_eig, self.nblocks), highlight_St=highlight_St)
            self.plot_modes(st_target=plot_st_target, n_modes=min(plot_n_modes_spatial, self.nblocks))
            self.plot_eig_complex_plane(n_modes=min(plot_n_modes_spatial, self.nblocks), st_target=plot_st_target)
            self.plot_time_coeffs(st_target=plot_st_target)  # Default plots mode 0

            if perform_verifications:
                print("\n--- Performing Additional Verifications ---")
                # Use the same plot_st_target for verifications, or the dominant one if None
                verification_st_target = plot_st_target
                if verification_st_target is None:
                    # Find dominant St if not provided (similar to how plot_modes does it)
                    if self.lambda_values is not None and self.St is not None:
                        valid_peaks_indices = np.where(self.St > 0.1)[0]
                        if valid_peaks_indices.size > 0:
                            lambda_at_valid_peaks = self.lambda_values[valid_peaks_indices, 0]
                            if lambda_at_valid_peaks.size > 0:
                                dominant_peak_idx_in_subset = np.argmax(lambda_at_valid_peaks)
                                actual_dominant_idx = valid_peaks_indices[dominant_peak_idx_in_subset]
                                verification_st_target = self.St[actual_dominant_idx]
                        if verification_st_target is None:  # Fallback if no peak > 0.1 or other issues
                            verification_st_target = self.St[np.argmax(self.lambda_values[:, 0])]

                self.plot_cumulative_energy_per_frequency(st_target=verification_st_target)
                self.check_spatial_mode_orthogonality(st_target=verification_st_target)
                self.check_temporal_coefficient_orthogonality(st_target=verification_st_target)
                if hasattr(self, "qhat") and self.qhat is not None and self.qhat.size > 0:
                    self.plot_reconstruction_error_per_frequency(st_target=verification_st_target)
                    self.plot_reconstruction_comparison_per_frequency(st_target=verification_st_target, block_idx_to_plot=0)  # Plot for block 0 by default
                else:
                    print("Skipping q_hat reconstruction plots as self.qhat is not available.")

            end_total_time = time.time()
            print(f"\nSPOD analysis completed successfully in {end_total_time - start_total_time:.2f} seconds.")
        except Exception as e:
            print(f"\nError during SPOD analysis: {str(e)}")
            import traceback

            print("\nTraceback:")
            traceback.print_exc()
            print("\nPlease check the inputs and try again.")
            raise

    """Class for performing Spectral Proper Orthogonal Decomposition (SPOD) analysis.

    **Expected Input Data Structure:**

    The core analysis methods (compute_fft_blocks, perform_spod) expect the 
    primary input data (e.g., pressure, velocity) to be preprocessed into a 
    2D NumPy array `q` stored in `self.data['q']`. 

    The required format for `self.data['q']` is:
        - Shape: `(Ns, Nspatial)`
        - `Ns`: Number of time snapshots.
        - `Nspatial`: Total number of spatial points (e.g., Nx * Ny for a 2D grid).
        - The first dimension (axis 0) must represent time.
        - The second dimension (axis 1) must represent the flattened spatial domain.
        - **Crucially, the flattening of the spatial points must be consistent 
          across all time snapshots.**

    Additionally, the following need to be provided in `self.data`:
        - `x`: 1D NumPy array of coordinates for the first spatial dimension (length Nx).
        - `y`: 1D NumPy array of coordinates for the second spatial dimension (length Ny).
        - `Nx`, `Ny`: Integers representing the dimensions of the original spatial grid.
        - `dt`: Float representing the time step between snapshots.

    The `load_jetles_data` function in this script handles loading from a specific 
    HDF5 format and performs the necessary transpose and reshape. If loading from
    a different source (like CGNS), you would need to implement a similar loading 
    function that extracts the data and metadata, then reshapes the primary data 
    variable into the required `(Ns, Nspatial)` format before assigning it and 
    the other metadata to `self.data`.
    """

    def __init__(self, file_path, nfft=128, overlap=0.5, results_dir=RESULTS_DIR_SPOD, figures_dir=FIGURES_DIR_SPOD, blockwise_mean=False, normvar=False, window_norm="power", window_type="hamming", data_loader=None, spatial_weight_type="auto"):
        super().__init__(file_path=file_path, nfft=nfft, overlap=overlap, results_dir=results_dir, figures_dir=figures_dir, data_loader=data_loader, spatial_weight_type=spatial_weight_type)
        self.blockwise_mean = blockwise_mean
        self.normvar = normvar
        self.window_norm = window_norm
        self.window_type = window_type
        # SPOD-specific fields
        self.phi = np.array([])
        self.lambda_values = np.array([])
        self.frequencies = np.array([])
        self.psi = np.array([])
        self.St = np.array([])
        self.dst = 0.0
        self.L = 1.0
        self.U = 1.0
        """Initialize the SPOD analyzer.

        Args:
            file_path (str): Path to the HDF5 data file.
            nfft (int): Number of snapshots per FFT block.
            overlap (float): Overlap fraction between blocks (0 to < 1).
            results_dir (str): Directory to save numerical results.
            figures_dir (str): Directory to save plots.
            blockwise_mean (bool): If True, use blockwise mean subtraction.
            normvar (bool): If True, normalize by variance.
            window_norm (str): Normalization for window function ('power' or 'amplitude').
            window_type (str): Type of window ('hamming', 'hann', 'rectangular').
            data_loader (callable, optional): Custom data loading function.
            spatial_weight_type (str): Type of spatial weighting ('polar', 'uniform', 'auto').
        """

    def load_and_preprocess(self):
        super().load_and_preprocess()
        # Set normalization constants for Strouhal number
        if "cavity" in self.file_path.lower():
            self.L = 0.0381
            self.U = 230.0
            print(f"Cavity case detected: Using L={self.L} m, U={self.U} m/s for Strouhal normalization.")
        else:
            self.L = 1.0
            self.U = 1.0
            print("Jet case or unknown: Using L=1, U=1 for Strouhal normalization.")
        # Calculate Strouhal vector
        self.fs = 1 / self.data["dt"]
        f = np.linspace(0, self.fs - self.fs / self.nfft, self.nfft)
        St = f * self.L / self.U
        self.St = St[0 : self.nfft // 2 + 1]
        self.dst = self.St[1] - self.St[0]
        self.strouhal = St

    def perform_spod(self):
        """Perform SPOD analysis (eigenvalue decomposition) for each frequency."""
        if self.qhat.size == 0:
            raise ValueError("FFT blocks not computed. Call compute_fft_blocks() first.")

        start_time = time.time()
        # Total number of spatial points
        nq = self.data["Nx"] * self.data["Ny"]
        # Number of frequencies to compute (only positive frequencies 0 to fs/2)
        n_freq = self.nfft // 2 + 1

        # Initialize arrays to store results
        # Eigenvalues (energy) for each mode at each frequency
        self.lambda_values = np.zeros((n_freq, self.nblocks))
        # Spatial modes for each mode at each frequency
        self.phi = np.zeros((n_freq, nq, self.nblocks), dtype=complex)
        # Time coefficients for each mode at each frequency
        self.psi = np.zeros((n_freq, self.nblocks, self.nblocks), dtype=complex)

        print("Performing SPOD for each frequency...")
        # Compute SPOD for each frequency f in the one-sided spectrum (0 to fs/2)
        for i in range(n_freq):
            # Extract FFT data for the current frequency i
            # qhat has shape [frequency, space, block]
            # We need [space, block] for spod_function
            qhat_freq = self.qhat[i, :, :]

            # Call the core SPOD function for this frequency
            phi_freq, lambda_freq, psi_freq = spod_function(qhat_freq, self.nblocks, self.dst, self.W, return_psi=True)

            # Store results
            self.phi[i, :, :] = phi_freq
            self.lambda_values[i, :] = lambda_freq
            self.psi[i, :, :] = psi_freq

            # Print progress (optional)
            if (i + 1) % 10 == 0 or i == n_freq - 1:
                print(f"  Processed frequency {i + 1}/{n_freq} (St = {self.St[i]:.4f})")

        print(f"SPOD eigenvalue decomposition completed in {time.time() - start_time:.2f} seconds")

    def run_analysis(self, plot_st_target=None, plot_n_modes_eig=10, plot_n_modes_spatial=4, use_disk_cache=True, perform_verifications=True):
        print("Starting SPOD analysis...")
        start_total_time = time.time()

        self.load_and_preprocess()
        self.compute_fft_blocks()
        self.perform_spod()
        self.save_results()

        print("\nGenerating visualizations...")
        highlight_St = None

        if plot_st_target is None:
            # Find all local maxima (peaks) in mode 1
            peaks, _ = find_peaks(self.lambda_values[:, 0])
            # Filter peaks to those with St > 0.1
            valid_peaks = [i for i in peaks if self.St[i] > 0.1]
            if valid_peaks:
                # Take the peak with the highest eigenvalue among valid peaks
                idx_peak = valid_peaks[np.argmax(self.lambda_values[valid_peaks, 0])]
                plot_st_target = self.St[idx_peak]
                highlight_St = plot_st_target
                print(f"No target St provided, plotting modes for dominant PEAK St > 0.1: {plot_st_target:.4f}")
            else:
                # Fallback: just use the global maximum
                dominant_freq_idx = np.argmax(self.lambda_values[:, 0])
                plot_st_target = self.St[dominant_freq_idx]
                highlight_St = plot_st_target
                print(f"No St > 0.1 found, plotting modes for dominant St: {plot_st_target:.4f}")
        else:
            highlight_St = plot_st_target

        self.plot_eigenvalues(n_modes=min(plot_n_modes_eig, self.nblocks), highlight_St=highlight_St)
        self.plot_modes(st_target=plot_st_target, n_modes=min(plot_n_modes_spatial, self.nblocks))
        self.plot_eig_complex_plane(n_modes=min(plot_n_modes_spatial, self.nblocks), st_target=plot_st_target)
        self.plot_time_coeffs(st_target=plot_st_target)
        if perform_verifications:
            print("\n--- Performing Additional Verifications ---")
            # Use the same plot_st_target for verifications, or the dominant one if None
            verification_st_target = plot_st_target
            if verification_st_target is None:
                # Find dominant St if not provided (similar to how plot_modes does it)
                if self.lambda_values is not None and self.St is not None:
                    valid_peaks_indices = np.where(self.St > 0.1)[0]
                    if valid_peaks_indices.size > 0:
                        lambda_at_valid_peaks = self.lambda_values[valid_peaks_indices, 0]
                        if lambda_at_valid_peaks.size > 0:
                            dominant_peak_idx_in_subset = np.argmax(lambda_at_valid_peaks)
                            actual_dominant_idx = valid_peaks_indices[dominant_peak_idx_in_subset]
                            verification_st_target = self.St[actual_dominant_idx]
                    if verification_st_target is None:  # Fallback if no peak > 0.1 or other issues
                        verification_st_target = self.St[np.argmax(self.lambda_values[:, 0])]

            self.plot_cumulative_energy_per_frequency(st_target=verification_st_target)
            self.check_spatial_mode_orthogonality(st_target=verification_st_target)
            self.check_temporal_coefficient_orthogonality(st_target=verification_st_target)
            if hasattr(self, "qhat") and self.qhat is not None and self.qhat.size > 0:
                self.plot_reconstruction_error_per_frequency(st_target=verification_st_target)
                self.plot_reconstruction_comparison_per_frequency(st_target=verification_st_target, block_idx_to_plot=0)  # Plot for block 0 by default
            else:
                print("Skipping q_hat reconstruction plots as self.qhat is not available.")

        end_total_time = time.time()
        print(f"\nSPOD analysis completed successfully in {end_total_time - start_total_time:.2f} seconds.")


# Example usage when the script is run directly
if __name__ == "__main__":
    # --- Configuration ---
    data_file = "./data/jetLES_small.mat"  # Updated data path
    # data_file = "./data/jetLES.mat" # Path to your data file
    # data_file = "./data/cavityPIV.mat" # Path to your data file

    results_dir = "./preprocess"  # Directory for HDF5 results
    figures_dir = "./figs"  # Directory for plots
    # Default parameters
    nfft_param = 128  # FFT block size
    overlap_param = 0.5  # Overlap fraction (50%)
    # Optional: Specify a frequency target for mode plots
    # If None, it will plot modes at the frequency with peak energy in Mode 1.
    freq_target_for_plots = None
    # ---------------------
    # Set case-specific parameters for cavity (to match MATLAB reference)
    if "cavity" in data_file.lower():
        nfft_param = 256
        overlap_param = 128 / 256  # 0.5
        window_type_param = "sine"  # Sine window for cavity, as in MATLAB
        spatial_weight_type_param = "uniform"  # Rectangular grid for cavity
        print("Cavity case detected: Using nfft=256, overlap=128 (50%), sine window to match MATLAB reference.")
    elif "jet" in data_file.lower():
        window_type_param = "hamming"  # Default for jet case
        spatial_weight_type_param = "polar"  # Cylindrical grid for jet
        print("Jet case detected: Using default nfft, overlap, and Hamming window.")
    else:
        window_type_param = "hamming"
        spatial_weight_type_param = "uniform"
        print("Unknown case: Using default nfft, overlap, and Hamming window.")
    # Check if data file exists
    if not os.path.exists(data_file):
        print(f"Error: Data file not found at '{data_file}'")
        exit()

    # Set case-specific data loader
    if "cavity" in data_file.lower():
        data_loader_param = load_mat_data
        print("Cavity case detected: Using load_mat_data.")
    elif "jet" in data_file.lower():
        data_loader_param = load_jetles_data
        print("Jet case detected: Using load_jetles_data.")
    else:
        data_loader_param = load_mat_data
        print("Unknown case: Using load_mat_data.")

    # Create SPOD analyzer instance
    spod_analyzer = SPODAnalyzer(file_path=data_file, nfft=nfft_param, overlap=overlap_param, results_dir=results_dir, figures_dir=figures_dir, window_type=window_type_param, data_loader=data_loader_param, spatial_weight_type=spatial_weight_type_param)

    # Run the full analysis and plotting pipeline
    spod_analyzer.run_analysis(
        plot_st_target=freq_target_for_plots,
        plot_n_modes_eig=10,  # Number of modes in eigenvalue plot
        plot_n_modes_spatial=4,  # Number of modes in spatial plot
    )
